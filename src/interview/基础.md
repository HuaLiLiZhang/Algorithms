## 基础


### 读扩散和写扩散
#### 写扩散(Push)
该方式为每个用户维护一个订阅列表，记录该用户订阅的消息索引（一般为消息ID、类型、发表时间等一些元数据）。每当用户发布消息时，都会去更新其follower的订阅列表。
优点：读很轻。初始化时仅需要读取自己的inbox即可。
缺点：写很重。每发布一个消息，会导致大量的写操作。
注：一般来说，用户发布消息，并不会更新所有followers的订阅列表，仅更新在线followers即可。

#### 读扩散(Pull)
该方式为每个用户维护一个发送列表，记录该用户所有发表过的消息索引。
优点：写很轻，节省空间。用户每发布一条消息，仅需更新自己的outbox。
缺点：读操作很重，计算量大。假设你收听了1k用户，则初始化时，需要从1k个用户的outbox拉取消息，然后计算获得最新的n条消息。

#### 混合模式(Push+Pull)
该方式既为读写扩散的结合，根据用户followers的数量来决定是读扩散还是写扩散。例如followers大于1k的，则使用读扩散，否则使用写扩散。


### string 的 intern
如果字符串常量池已经包含一个等于此String对象的字符串，则返回字符串常量池中这个字符串的引用, 否则将当前String对象的引用地址（堆中，即当前字符串）添加到字符串常量池中并返回。

### hashmap
1. put
    - 1.7版本在多线程下put后的扩容过程（transfer方法）会死循环，新链表的顺序跟旧的链表是完全相反的，因此可能会发生死循环
    - 1.8版本链表顺序一样，不会产生死循环

### concurrenthashmap
1. Node数组+链表+红黑树的数据结构
2. 扩容时机
    - 数组tab长度小于64，且某个链表长于8，则扩容
    - 数组tab长度大于等于64，且某个链表长于8，则转变为红黑树

### ConcurrentLinkedQueue
1. 使用约定
    - 不允许null入列
    - 在入队的最后一个元素的next为null
    - 队列中所有未删除的节点的item都不能为null且都能从head节点遍历到
    - 删除节点是将item设置为null, 队列迭代时跳过item为null节点
    - head节点跟tail（多线程不一定是最后一个，可能是倒数第二个）不一定指向头节点或尾节点，可能存在滞后性
2. 入列
    - 死循环，就是不停使用cas判断直到添加元素入队成功
    - 死循环中运行casNext和casTail方法，确保队列在 入列时/tail队尾在移动改变时 是原子操作
    - 线程1线程2同时入列：利用cas解决碰撞，线程安全
    - 线程1遍历，线程2入列：线程1遍历，线程2很有可能进行入列出列操作， 所以ConcurrentLinkedQueue 的size（size()方法是O（n）的，且线程不安全）是变化。换句话说，要想安全遍历ConcurrentLinkedQueue 队列，必须额外加锁。
3. 出列
    - 死循环，不断cas将操作节点的item设置null， 表示出列成功
    - 一旦出列成功需要对head进行移动

### OOM如何排查？
1. 原因
    - 分配的少了：比如虚拟机本身可使用的内存（一般通过启动时的VM参数指定）太少。
    - 应用用的太多，并且用完没释放，浪费了。此时就会造成内存泄露或者内存溢出。
2. 举例
    - java.lang.OutOfMemoryError: Java heap space ------>java堆内存溢出，此种情况最常见，一般由于内存泄露或者堆的大小设置不当引起。对于内存泄露，需要通过内存监控软件查找程序中的泄露代码，而堆大小可以通过虚拟机参数-Xms,-Xmx等修改。
    - java.lang.OutOfMemoryError: PermGen space 或 java.lang.OutOfMemoryError：MetaSpace ------>java方法区，（java8 元空间）溢出了，一般出现于大量Class或者jsp页面，或者采用cglib等反射机制的情况，因为上述情况会产生大量的Class信息存储于方法区。此种情况可以通过更改方法区的大小来解决，使用类似-XX:PermSize=64m -XX:MaxPermSize=256m的形式修改。另外，过多的常量尤其是字符串也会导致方法区溢出。
    - java.lang.StackOverflowError ------> 不会抛OOM error，但也是比较常见的Java内存溢出。JAVA虚拟机栈溢出，一般是由于程序中存在死循环或者深度递归调用造成的，栈大小设置太小也会出现此种溢出。可以通过虚拟机参数-Xss来设置栈的大小。

### 自己实现一个阻塞队列
一个reentrantLock，派生两个condition，一个notEmpty，一个notFull，一个object数组存放元素，一个size标识队列规模（实际的元素个数，非最大值），一个head和tail，标识头尾元素的下标
1. 初始化：object数组初始化为size大小
2. put方法：先lock.lock()，当size == object数组的len时，代表队列满，notFull.await()，直到被唤醒；放置元素在tail位置，tail+1，size++；然后notEmpty.signal()，唤醒可能在等素的线程；最后在finally块中释放锁
3. take方法：先lock.lock()，当size == 0时，代表队列空，notEmpty.await()，直到被唤醒；取出head处元素，强转为E；head++，size++；然后notFull.signal()，唤醒可能在等素的线程；最后在finally块中释放锁
4. 注意：当head或tail为数组长度时，要及时更新为0

### 多线程交替打印
1. LockSupport.park()和LockSupport.unpark(thread)方法，每次线程打印后调用park方法挂起自己，同时unpark另一个线程
2. synchronized方法，同一把锁，每个线程打印后，notify另一个，自己wait；另一个线程被唤醒后，打印，再notify，然后自己wait
3. 阻塞队列（长度为1的两个ArrayBlockingQueue，或两个SynchronousQueue），线程从一个队列中取，同时往另一个队列塞，队列为空则自动阻塞
4. 不使用锁，用一个AtomicInteger，一个线程在其为偶数时打印，一个奇数打印，打印完++
5. ReentrantLock和Condition，每个线程先打印，然后调用condition的signal，唤醒另一个线程；再调用wait，自己挂起，等待被唤醒

### 零拷贝
1. mmap内存映射，比普通的read调用节省从内核缓冲区到用户空间缓冲区的拷贝
2. sendfile（linux 2.1引入）将文件传递到套接字上（反过来不行），其实现为将带有文件位置和长度信息的缓冲区描述符添加socket缓冲区去，这一步不会将内核中的数据拷贝到socket缓冲区中


### 同步队列 
节点入队
1. 当前解冻的prev指向前任tail
2. cas将tail指向当前节点
3. 前任tail的next执行当前解冻
如果执行到2，时间片到期，此时前驱节点的next还是null，会存在漏唤醒问题。而prev的赋值操作先于cas执行，因此通过prev总能找到

### hashmap红黑树阈值为8原因：
随机hashCode下，转化为红黑树的概率服从泊松分布，阈值为8时概率为0.00000006

### 字符串用常量的原因
1. 字符串常量池的实现，多个变量指向池中的同一个，性能高
2. 安全性，不可变，不会被黑客改变
3. 线程安全，多个线程不需要同步
4. hashCode是固定的，适合作为map的键

### 创建线程的几种方式
1. 继承Thread类
2. 实现Runnable接口
3. 实现Callable接口
4. 线程池

### 秒杀系统
1. 流量过滤
    - 活动开始前前端页面的 Button 置灰，防止活动未开始无效的点击产生流量
    - 前端添加验证码或者答题，防止瞬间产生超高的流量
    - 活动校验，既然是活动，那么活动的参与用户，参加条件，用户白名单之类的要首先做一层校验拦截，还有其他的比如用户终端、IP 地址、参与活动次数、黑名单用户的校验。
    - 非法请求拦截
    - 限流，假设秒杀 10000 件商品，我们有 10 台服务器，单机的 QPS 在 1000，那么理论上 1 秒就可以抢完，针对微服务就可以做限流配置，避免后续无效的流量打到数据库造成不必要的压力。（可以降级和熔断）
2. 性能优化
    - 页面静态化，参与秒杀活动的商品一般都是已知的，可以针对活动页面做静态化处理，缓存到 CDN。
    - 活动预热，针对活动的活动库存可以独立出来，不和普通的商品库存共享服务，活动库存活动开始前提前加载到 redis，查询全部走缓存，最后扣减库存再视情况而定。
    - 独立部署，资源充足的情况下可以考虑针对秒杀活动单独部署一套环境
3. 防止超卖
    - 首先查询 redis 缓存库存是否充足
    - 先扣库存再落订单数据，可以防止订单生成了没有库存的超卖问题
    - 扣库存的时候先扣数据库库存，再扣减 redis 库存，保证在同一个事务里，无论两者哪一个发生了异常都会回滚。

### 怎么预防CSRF？
用csrf防止cookie被盗用，


### LinkedBlockingQueue和ConcurrentLinedQueue的区别，为什么要有两个？
有block则代表提供了阻塞api；有concurrent代表方法加了锁，线程安全；有queue则是单向队列，有deque则是双端队列；有linked是基于链表实现，有array是基于数组实现的


### 频繁GC
1. 可能是内存泄漏，内存使用完了没释放；jmap（jmap -histo  pid）看对象的存活，哪些对象数太多
2. 内存设置问题，jstat看看，根据业务，新生代、老年代和永久代的设置情况

### future，futureTask的区别
future是个接口，不同的实现是不一样的，常见的是FutureTask（线程池提交Callback）是直接依赖LockSupport.park(nanos)/unpark的，Lock锁/AQS也是依赖这个。get时会检查有没有完成，没完成会进入阻塞，等到任务的流程跑完后，会塞入结果，然后唤醒等待的线程。另一个常见的是CompletableFuture，get的时候的特点是先自旋一定次数，尝试获取结果，拿不到再进入阻塞

### select poll和epoll的区别
select和poll差不多，一个是数组，一个是链表，所以后者没有数量的限制；epoll多注册了一个ctrl事件监听。套接字是操作系统在管理，所以硬件的中断反馈给操作系统，进程从操作系统读取套接字的fd，所以有一个内存拷贝的过程，select和poll是轮询每个套接字，每次都要全部拷贝，而epoll是在初始化时拷贝，每次事件触发时直接响应，不需要再复制

### 有一个请求去调用了服务A，A中需要向数据库写入数据，其中A里面又调用了服务B，B中也向服务器写入了一些数据，当A成功调用B之后，B正常执行了，A的操作发生了异常，A操作的数据可以正常回滚，那么问题是B服务的事务如何与A保持一致呢？
1. 结合MQ消息中间件实现的可靠消息最终一致性
    - 可靠消息最终一致性，需要业务系统结合MQ消息中间件实现，在实现过程中需要保证消息的成功发送及成功消费。即需要通过业务系统控制MQ的消息状态
2. TCC补偿性事务解决方案（借助事务管理模块，做全局事务提交的决定）
    - TCC补偿性，分为三个阶段TRYING-CONFIRMING-CANCELING。每个阶段做不同的处理。
    - TRYING阶段主要是对业务系统进行检测及资源预留
    - CONFIRMING阶段是做业务提交，通过TRYING阶段执行成功后，再执行该阶段。默认如果TRYING阶段执行成功，CONFIRMING就一定能成功。
    - CANCELING阶段是回对业务做回滚，在TRYING阶段中，如果存在分支事务TRYING失败，则需要调用CANCELING将已预留的资源进行释放。
3. 最大努力通知型方案
    - 这种方案也是结合MQ进行实现，例如：通过MQ发送http请求，设置最大通知次数。达到通知次数后即不再通知。主要用在与第三方系统通讯时
4. 补偿模式
    - 提供回滚接口供调用方使用


### 订单有几个属性，用户user_id，下单日期date，满足以下场景，如何建立最少的索引
1. 查询某个用户的所有订单
2. 查询某一天的所有订单
3. 查询某一天某个用户的所有订单
    - date和user_id_date两个索引（否则就得是user_id和date_user_id两个），但date的选择性没有user_id更好，因此选前者


### TPS、RPS和QPS的区别
- TPS：Transactions Per Second（每秒传输的事物处理个数），即服务器每秒处理的事务数。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。
- QPS：Queries Per Second意思是“每秒查询率”，是一台服务器每秒能够响应的查询次数，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。
- 如果是容量场景，假设n个接口都是查询接口，且这个接口内部不会再去请求其它接口，qps=n*tps
- RPS 代表吞吐率，即 Requests Per Second，指的是某个并发用户数下单位时间内处理的请求数，等效于QPS

## 算法题
- 加油站
- k个一组翻转单链表
- 二叉树第k层偶数和
- 判断一个数组数据是否是二叉搜索树的后续遍历
- 单例模式，
- 两个list的区间交集
- 二叉树锯齿形层次遍历
- 字典序的第k小数字
- 二叉树以中序遍历方式转换成双向链表，空间O(1)
- 给定一个n*m的数组，每个位置一个分数，求左上到右下的最大分数
- 将一个无序数组插入1g个元素的有序数组中
- 对一个100g的文件去重
- 可怜的小猪
- 盛最多水的容器
- 174地下城游戏

### 实现lru
一个map（键为元素的值，值为node本身），内部放node，实现O(1)时间内判断是否在集合中；节点采用双端队列，方便删除、新增节点；
1. get：首先判断map中是否存在元素，不存在返回-1；存在则从map中get节点，把节点move2Head，返回节点的值即可
2. put：首先判断map中是否存在，不存在则新建节点并添加链表的头，并将其添加到map；存在则更新map中的值，并把节点move2Head
- 注意当判定size >= capacity时，要找到tail的前置节点curNode，remove map中的节点，并删除curNode
3. 私有方法
- deleteNode：找到pre和next节点，相互连接，把curNode的pre和next置为null，size--
- addHeadNode：处理前置哨兵head，让head和curNode相连，原先的head.next连接到curNode的后面
- move2Head：先deleteNode，再add2Head

### 海量的号码存在一个大文件里，机器内存只有512M，怎么去重
用一个bit代表一个数字

### 有2T的文件，一半以上数据重复，1T的内存核无限的CPU，如何去重
维护很多个二叉树，存在抛弃，最后再进行一次去重

### 给定m个不重复字符[a,b,c]，以及一个长度为n的字符串，问是否能在这个字符串中找到一个长度为m的连续子串，要求子串由m个字符组成，顺序不要求
- TODO



### 设计一个内存计数器，统计有限个高频词汇的访问量，实现统计和查询两个方法
1. 用threadLocal保存每个线程的long副本，无锁自增。需要解决get求值问题，需要注意
 - 需要try catch，以免线程退出导致threadlocal销毁
 - 通过threadFactory拿到线程池创建时的所有线程和其的threadLocal变量
2. 每个线程单独统计（不需要锁和cas，直接加就行），get时累加每个线程的值
3. 并发量不大，直接用atomic包；并发大时用LongAdder，将对单个值的cas分散到数组中，自旋降低，每次get都计算数组的和


### jvm的命名空间 
- 每个类加载器都有自己的命名空间。和我们Java中的Package的概念是一样的，和XML中的namespace的概念类似。同一个命名空间内的类是相互可见的，命名空间由该加载器及所有父加载器所加载的类组成。
- 子加载器加载的类能看见父加载器的类，但是父加载器看不到子加载器加载的类
- 在同一个命名空间中，不会出现类的完整名字（包括类的包名）相同的两个类；在不同的命名空间中，有可能会出现类的完整名字（包括类的包名）相同的两个类。


### 系统线程状态 (Native Thread Status)
####deadlock
死锁线程，一般指多个线程调用期间进入了相互资源占用，导致一直等待无法释放的情况。

####runnable 
一般指该线程正在执行状态中，该线程占用了资源，正在处理某个操作，如通过SQL语句查询数据库、对某个文件进行写入等。

#### blocked
线程正处于阻塞状态，指当前线程执行过程中，所需要的资源长时间等待却一直未能获取到，被容器的线程管理器标识为阻塞状态，可以理解为等待资源超时的线程。

#### waitting on condition（线程状态为WAITING或TIMED_WAITING）
线程正处于等待资源或等待某个条件的发生，具体的原因需要结合下面堆栈信息进行分析。
1. 如果堆栈信息明确是应用代码，则证明该线程正在等待资源，一般是大量读取某种资源且该资源采用了资源锁的情况下，线程进入等待状态，等待资源的读取，或者正在等待其他线程的执行等。
2. 如果发现有大量的线程都正处于这种状态，并且堆栈信息中得知正等待网络读写，这是因为网络阻塞导致线程无法执行，很有可能是一个网络瓶颈的征兆：
    - 网络非常繁忙，几乎消耗了所有的带宽，仍然有大量数据等待网络读写；
    - 网络可能是空闲的，但由于路由或防火墙等原因，导致包无法正常到达；
    - 所以一定要结合系统的一些性能观察工具进行综合分析，比如netstat统计单位时间的发送包的数量，看是否很明显超过了所在网络带宽的限制；观察CPU的利用率，看系统态的CPU时间是否明显大于用户态的CPU时间。这些都指向由于网络带宽所限导致的网络瓶颈。
3. 还有一种常见的情况是该线程在 sleep，等待 sleep 的时间到了，将被唤醒。
   
#### waiting for monitor entry 或 in Object.wait()  (线程状态为BLOCKED)
每个Monitor在某个时刻只能被一个线程拥有，该线程就是 "Active Thread"，而其他线程都是 "Waiting Thread"，分别在两个队列 "Entry Set"和"Waint Set"里面等待。其中在 "Entry Set" 中等待的线程状态是 waiting for monitor entry，在 "Wait Set" 中等待的线程状态是 in Object.wait()。
1.  "Entry Set"里面的线程。
    - 我们称被 synchronized 保护起来的代码段为临界区，
    - 当一个线程申请进入临界区时，它就进入了 "Entry Set" 队列中，这时候有两种可能性：
        - 该Monitor不被其他线程拥有，"Entry Set"里面也没有其他等待的线程。本线程即成为相应类或者对象的Monitor的Owner，执行临界区里面的代码；此时在Thread Dump中显示线程处于 "Runnable" 状态。
        - 该Monitor被其他线程拥有，本线程在 "Entry Set" 队列中等待。此时在Thread Dump中显示线程处于 "waiting for monity entry" 状态。
    - 临界区的设置是为了保证其内部的代码执行的原子性和完整性，但因为临界区在任何时间只允许线程串行通过，这和我们使用多线程的初衷是相反的。如果在多线程程序中大量使用synchronized，或者不适当的使用它，会造成大量线程在临界区的入口等待，造成系统的性能大幅下降。如果在Thread Dump中发现这个情况，应该审视源码并对其进行改进。

2. "Wait Set"里面的线程
    - 当线程获得了Monitor，进入了临界区之后，如果发现线程继续运行的条件没有满足，它则调用对象（通常是被synchronized的对象）的wait()方法，放弃Monitor，进入 "Wait Set"队列。只有当别的线程在该对象上调用了 notify()或者notifyAll()方法，"Wait Set"队列中的线程才得到机会去竞争，但是只有一个线程获得对象的Monitor，恢复到运行态。"Wait Set"中的线程在Thread Dump中显示的状态为 in Object.wait()。通常来说，当CPU很忙的时候关注 Runnable 状态的线程，反之则关注 waiting for monitor entry 状态的线程。


### 线上问题排查
1. jstack（1.5）生成thread dump，记录JVM在某一时刻各个线程执行的情况，是一个文本文件
    - 需要在多个时间段提出多个 Thread Dump信息，然后综合进行对比分析，单独分析一个文件是没有意义的。
2. jstat命令用于见识虚拟机各种运行状态信息的命令行工具。它可以显示本地或者远程虚拟机进程中的类装载、内存、垃圾收集、jit编译等运行数据
3. "VM Thread" 是 JVM 自身启动的一个线程, 它主要用来协调其它线程达到安全点(Safepoint)
4. jmap生成Heap Dump文件
    - jhat 是JDK自带的用于分析JVM Heap Dump文件的工具，使用下面的命令可以将堆文件的分析结果以HTML网页的形式进行展示：jhat <heap-dump-file>
    

####　具体场景
1. CPU占用率很高，响应很慢
先找到占用CPU的进程，然后再定位到对应的线程，最后分析出对应的堆栈信息。
在同一时间多次使用上述的方法，然后进行对比分析，从代码中找到问题所在的原因。如果线程指向的是"VM Thread"或者无法从代码中直接找到原因，就需要进行内存分析。
2. CPU占用率不高，但响应很慢
在整个请求的过程中多次执行Thread Dump然后进行对比，取得 BLOCKED 状态的线程列表，通常是因为线程停在了I/O、数据库连接或网络连接的地方。
3. 系统线程状态为 deadlock
线程处于死锁状态，将占用系统大量资源。
4. 系统线程状态为 waiting for monitor entry 或 in Object.wait()
系统线程处于这种状态说明它在等待进入一个临界区，此时JVM线程的状态通常都是 java.lang.Thread.State: BLOCKED。
如果大量线程处于这种状态的话，可能是一个全局锁阻塞了大量线程。如果短期内多次打印Thread Dump信息，发现 waiting for monitor entry 状态的线程越来越多，没有减少的趋势，可能意味着某些线程在临界区里呆得时间太长了，以至于越来越多新线程迟迟无法进入。
5. 系统线程状态为 waiting on condition
系统线程处于此种状态说明它在等待另一个条件的发生来唤醒自己，或者自己调用了sleep()方法。此时JVM线程的状态通常是java.lang.Thread.State: WAITING (parking)（等待唤醒条件）或java.lang.Thread.State: TIMED_WAITING (parking或sleeping)（等待定时唤醒条件）。
如果大量线程处于此种状态，说明这些线程又去获取第三方资源了，比如第三方的网络资源或读取数据库的操作，长时间无法获得响应，导致大量线程进入等待状态。因此，这说明系统处于一个网络瓶颈或读取数据库操作时间太长。
6. 系统线程状态为 blocked
线程处于阻塞状态，需要根据实际情况进行判断。


### java反射如何实现
基于4个类：class（类对象），Constructor（构造器对象，包括无参数和有参数的构造函数），Field，Method
JVM层面能拿到class文件中的类内容，进而获取它的属性，方法，父类等

#### 性能问题
在反射调用方法的例子中，我们先后调用了Class.forName，Class.getMethod，以及Method.invoke三个操作。其中Class.forName 会调用本地方法，Class.getMethod 会遍历该类的公有方法。如果没有匹配到它还会遍历父级的公有方法，可以知道这两个操作非常耗费时间。
- Method.invoke 内部有两种实现，一个是 Native 版本，一个是 Java 版本；开始native版本，超过15次后编译成机器码，用java版本。Inflation 机制：java版本的生成需要比native长3倍，但生成之后，要比java的生成快20倍
- 需要检查方法可见性
- 需要校验参数
- 反射方法难以内联
- 因为动态加载的类型，所以无法进行JIT优化

#### 应用
- 反射让开发人员可以通过外部类的全路径名创建对象，并使用这些类，实现一些扩展的功能。
- 反射让开发人员可以枚举出类的全部成员，包括构造函数、属性、方法。以帮助开发者写出正确的代码。
- 测试时可以利用反射 API 访问类的私有成员，以保证测试代码覆盖率。 
- 反射机制是构建框架技术的基础所在，使用反射可以避免将代码写死在框架中。


### Java对异常的设计以及为何这么设计
1. error：Error是程序无法处理的错误，它是由JVM产生和抛出的，比如OutOfMemoryError、ThreadDeath等。这些异常发生时，Java虚拟机（JVM）一般会选择线程终止。
2. exception：Exception是程序本身可以处理的异常，这种异常分两大类运行时异常和非运行时异常。程序中应当尽可能去处理这些异常。
    - RuntimeException：运行时异常都是RuntimeException类及其子类异常，如NullPointerException、IndexOutOfBoundsException等，这些异常是不检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生。
    - 受检异常：非运行时异常是RuntimeException以外的异常，类型上都属于Exception类及其子类。从程序语法角度讲是必须进行处理的异常，如果不处理，程序就不能编译通过。如IOException、SQLException等以及用户自定义的Exception异常，一般情况下不自定义检查异常。
    
    
### 同步，异步，阻塞，非阻塞
同步异步针对于发起调用者
1. 同步和异步关注的是消息通信机制 (synchronous communication/ asynchronous communication)
    - 所谓同步，就是在发出一个*调用*时，在没有得到结果之前，该*调用*就不返回。但是一旦调用返回，就得到返回值了。
    - 而异步则是相反，*调用*在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在*调用*发出后，*被调用者*通过状态、通知来通知调用者，或通过回调函数处理这个调用。
2. 阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态.
    - 阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。
    - 非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。
    
### spring的注解
- @Component, @Service, @Controller, @Repository是spring注解，注解后可以被spring框架所扫描并注入到spring容器来进行管理
- @Component是通用注解，其他三个注解是这个注解的拓展，并且具有了特定的功能
- @Repository注解在持久层中，具有将数据库操作抛出的原生异常翻译转化为spring的持久层异常的功能。
- @Controller层是spring-mvc的注解，具有将请求进行转发，重定向的功能。
- @Service层是业务逻辑层注解，这个注解只是标注该类处于业务逻辑层。
- 用这些注解对应用进行分层之后，就能将请求处理，义务逻辑处理，数据库操作处理分离出来，为代码解耦，也方便了以后项目的维护和开发。


### spring事物传播行为（事物传播级别）7种
- PROPAGATION_REQUIRED	如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常见的选择。
- PROPAGATION_SUPPORTS	支持当前事务，如果当前没有事务，就以非事务方式执行。
- PROPAGATION_MANDATORY	使用当前的事务，如果当前没有事务，就抛出异常。
- PROPAGATION_REQUIRES_NEW	新建事务，如果当前存在事务，把当前事务挂起。
- PROPAGATION_NOT_SUPPORTED	以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。
- PROPAGATION_NEVER	以非事务方式执行，如果当前存在事务，则抛出异常。
- PROPAGATION_NESTED	如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。

### spring mvc从request到controller的过程
1. 请求打到DispatcherServlet
2. 处理器映射
    - SpringMVC在初始化的时候加入的各种处理器，对于请求到Controller的映射，比较重要的是HandlerMapping和HandlerAdapter，HandlerMapping是用来查找处理请求的对象，HandlerAdapter是用来处理请求参数
3. 对应的控制器处理
4. 对应的model
5. 返回对应的view给视图解析器
6. 返回视图给用户

### volatile用处，如何实现的
synchronized 关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而 volatile 关键字在某些情况下性能要优于 synchronized ，但是要注意 volatile 关键字是无法替代 synchronized 关键字的，因为 volatile 关键字无法保证操作的原子性。通常来说，使用 volatile 必须具备以下 2 个条件：

对变量的写操作不依赖于当前值

该变量没有包含在具有其他变量的不变式中


### 未解决
- 倒排索引的实现（提取关键词，建立关键词->记录的索引）
- gc回收频率（创建对象时需要分配内存空间，如果空间不足，触发GC）
- object类有哪些方法（hashcode、equals、toString、wait、带超时时间的wait、notify、notifyAll）
- 线程池锁如何关闭空闲线程 //TODO
- nio为何比bio快（节省了大量的调度开销）
- 文件内容如何直接读到内存空间里（内存映射，省下了内核缓存的数据拷贝）
- 锁升级流程（只升不降）
- 线程池参数，拒绝策略
- 动态代理
- 泛型，为什么有泛型擦除
- crm采用标记清理算法，如何解决内存碎片问题
- jvm内存模型中，线程为什么要内存副本
- volitile不保证原子性的后果
- CAS的原理，ABA问题的解决方案
- Spring Boot Starter怎么实现？如何自定义Starter
- 为什么LinkedList线程不安全
- 怎么保证缓存数据库一致？（延迟双删）
- 关系型和非关系型数据库区别
- 日志写满了如何排查，oom了如何排查
- rpc和http的区别，在不同场景下的应用，rpc一般用什么协议
- JVM堆的分区
- G1垃圾回收器
- 一个端口可以被多少个进程绑定
- 匿名内部类
- concurrenthashmap的get，如果正在扩容，是从原数组，还是新数组中获取的？（）
- thread有几种状态，和操作系统的对应关系
- 设计一个微服务需要注意什么问题
- completeFuture中主线程和子线程怎么通信
- aop有三种，可以运行时织入，编译时织入，类加载时织入，一般是第一种，基于JVM的动态代理
- undo和redo日志区别（redo即重做，undo即撤销还原）
- 
- redis的zset 二维结构，zset怎么使用会影响效率？（频繁的插入和删除）
- linux是如何启动的
- 分布式事物和共识算法
- g1是怎么计算价值的，怎么知道哪些区应该回收
- JVM堆区分布
- 主线程的上下文如何传递给子线程