## 基础
- 倒排索引的实现
- JVM调优
- spring事物传播行为（事物传播级别），例如转账行为失败，转账记录的流水日志不回滚
- 同步，异步，阻塞，非阻塞区别
- Java对异常的设计以及为何这么设计（error和Exception）
- gc回收频率（年轻代/老年代）
- git cherry-pick原理
- object类有哪些方法（hashcode、equals、toString、wait、带超时时间的wait、notify、notifyAll）
- service和component的区别
- spring mvc从request到controller的过程
- 线程池锁如何关闭空闲线程
- nio为何比bio快
- 文件内容如何直接读到内存空间里（内存映射，省下了内核缓存的数据拷贝）
- java反射如何实现
- 死锁如何排查
- 锁升级流程
- volatile用处，如何实现的
- hashmap的put怎么执行？8有什么变化？为什么线程不安全？hashtable呢
- concurrenthashmap为什么线程安全，怎么扩容，8有什么变化
- 线程池参数，拒绝策略
- 动态代理
- 泛型，为什么有泛型擦除
- crm采用标记清理算法，如何解决内存碎片问题
- jvm内存模型中，线程为什么要内存副本
- volitile不保证原子性的后果
- CAS的原理，ABA问题的解决方案
- Spring Boot Starter怎么实现？如何自定义Starter
- 为什么LinkedList线程不安全
- 怎么保证缓存数据库一致？（延迟双删）
- 关系型和非关系型数据库区别
- 日志写满了如何排查，oom了如何排查
- rpc和http的区别，在不同场景下的应用，rpc一般用什么协议
- JVM堆的分区
- G1垃圾回收器
- 一个端口可以被多少个进程绑定
- 匿名内部类
- concurrenthashmap的get，如果正在扩容，是从原数组，还是新数组中获取的？（）
- thread有几种状态，和操作系统的对应关系
- 设计一个微服务需要注意什么问题
- completeFuture中主线程和子线程怎么通信
- aop有三种，可以运行时织入，编译时织入，类加载时织入，一般是第一种，基于JVM的动态代理
- undo和redo日志区别（redo即重做，undo即撤销还原）
- waitting on condition问题
- jvm 的 namespace 
- redis的zset 二维结构，zset怎么使用会影响效率？（频繁的插入和删除）


### string 的 intern
如果字符串常量池已经包含一个等于此String对象的字符串，则返回字符串常量池中这个字符串的引用, 否则将当前String对象的引用地址（堆中）添加到字符串常量池中并返回。

### hashmap
1. put
    - 1.7版本在多线程下put后的扩容过程（transfer方法）会死循环，新链表的顺序跟旧的链表是完全相反的，因此可能会发生死循环
    - 1.8版本链表顺序一样，不会产生死循环

### concurrenthashmap
1. Node数组+链表+红黑树的数据结构
2. 扩容时机
    - 数组tab长度小于64，且某个链表长于8，则扩容
    - 数组tab长度大于等于64，且某个链表长于8，则转变为红黑树

### ConcurrentLinkedQueue
1. 使用约定
    - 不允许null入列
    - 在入队的最后一个元素的next为null
    - 队列中所有未删除的节点的item都不能为null且都能从head节点遍历到
    - 删除节点是将item设置为null, 队列迭代时跳过item为null节点
    - head节点跟tail（多线程不一定是最后一个，可能是倒数第二个）不一定指向头节点或尾节点，可能存在滞后性
2. 入列
    - 死循环，就是不停使用cas判断直到添加元素入队成功
    - 死循环中运行casNext和casTail方法，确保队列在 入列时/tail队尾在移动改变时 是原子操作
    - 线程1线程2同时入列：利用cas解决碰撞，线程安全
    - 线程1遍历，线程2入列：线程1遍历，线程2很有可能进行入列出列操作， 所以ConcurrentLinkedQueue 的size（size()方法是O（n）的，且线程不安全）是变化。换句话说，要想安全遍历ConcurrentLinkedQueue 队列，必须额外加锁。
3. 出列
    - 死循环，不断cas将操作节点的item设置null， 表示出列成功
    - 一旦出列成功需要对head进行移动

### OOM如何排查？
1. 原因
    - 分配的少了：比如虚拟机本身可使用的内存（一般通过启动时的VM参数指定）太少。
    - 应用用的太多，并且用完没释放，浪费了。此时就会造成内存泄露或者内存溢出。
2. 举例
    - java.lang.OutOfMemoryError: Java heap space ------>java堆内存溢出，此种情况最常见，一般由于内存泄露或者堆的大小设置不当引起。对于内存泄露，需要通过内存监控软件查找程序中的泄露代码，而堆大小可以通过虚拟机参数-Xms,-Xmx等修改。
    - java.lang.OutOfMemoryError: PermGen space 或 java.lang.OutOfMemoryError：MetaSpace ------>java方法区，（java8 元空间）溢出了，一般出现于大量Class或者jsp页面，或者采用cglib等反射机制的情况，因为上述情况会产生大量的Class信息存储于方法区。此种情况可以通过更改方法区的大小来解决，使用类似-XX:PermSize=64m -XX:MaxPermSize=256m的形式修改。另外，过多的常量尤其是字符串也会导致方法区溢出。
    - java.lang.StackOverflowError ------> 不会抛OOM error，但也是比较常见的Java内存溢出。JAVA虚拟机栈溢出，一般是由于程序中存在死循环或者深度递归调用造成的，栈大小设置太小也会出现此种溢出。可以通过虚拟机参数-Xss来设置栈的大小。

### 自己实现一个阻塞队列
一个reentrantLock，派生两个condition，一个notEmpty，一个notFull，一个object数组存放元素，一个size标识队列规模（实际的元素个数，非最大值），一个head和tail，标识头尾元素的下标
1. 初始化：object数组初始化为size大小
2. put方法：先lock.lock()，当size == object数组的len时，代表队列满，notFull.await()，直到被唤醒；放置元素在tail位置，tail+1，size++；然后notEmpty.signal()，唤醒可能在等素的线程；最后在finally块中释放锁
3. take方法：先lock.lock()，当size == 0时，代表队列空，notEmpty.await()，直到被唤醒；取出head处元素，强转为E；head++，size++；然后notFull.signal()，唤醒可能在等素的线程；最后在finally块中释放锁
4. 注意：当head或tail为数组长度时，要及时更新为0

### 多线程交替打印
1. LockSupport.park()和LockSupport.unpark(thread)方法，每次线程打印后调用park方法挂起自己，同时unpark另一个线程
2. synchronized方法，同一把锁，每个线程打印后，notify另一个，自己wait；另一个线程被唤醒后，打印，再notify，然后自己wait
3. 阻塞队列（长度为1的两个ArrayBlockingQueue，或两个SynchronousQueue），线程从一个队列中取，同时往另一个队列塞，队列为空则自动阻塞
4. 不使用锁，用一个AtomicInteger，一个线程在其为偶数时打印，一个奇数打印，打印完++
5. ReentrantLock和Condition，每个线程先打印，然后调用condition的signal，唤醒另一个线程；再调用wait，自己挂起，等待被唤醒

### 零拷贝
1. mmap内存映射，比普通的read调用节省从内核缓冲区到用户空间缓冲区的拷贝
2. sendfile（linux 2.1引入）将文件传递到套接字上（反过来不行），其实现为将带有文件位置和长度信息的缓冲区描述符添加socket缓冲区去，这一步不会将内核中的数据拷贝到socket缓冲区中


### 同步队列 
节点入队
1. 当前解冻的prev指向前任tail
2. cas将tail指向当前节点
3. 前任tail的next执行当前解冻
如果执行到2，时间片到期，此时前驱节点的next还是null，会存在漏唤醒问题。而prev的赋值操作先于cas执行，因此通过prev总能找到

### hashmap红黑树阈值为8原因：
随机hashCode下，转化为红黑树的概率服从泊松分布，阈值为8时概率为0.00000006

### 字符串用常量的原因
1. 字符串常量池的实现，多个变量指向池中的同一个，性能高
2. 安全性，不可变，不会被黑客改变
3. 线程安全，多个线程不需要同步
4. hashCode是固定的，适合作为map的键

### 创建线程的几种方式
1. 继承Thread类
2. 实现Runnable接口
3. 实现Callable接口
4. 线程池

### 秒杀系统
1. 流量过滤
    - 活动开始前前端页面的 Button 置灰，防止活动未开始无效的点击产生流量
    - 前端添加验证码或者答题，防止瞬间产生超高的流量
    - 活动校验，既然是活动，那么活动的参与用户，参加条件，用户白名单之类的要首先做一层校验拦截，还有其他的比如用户终端、IP 地址、参与活动次数、黑名单用户的校验。
    - 非法请求拦截
    - 限流，假设秒杀 10000 件商品，我们有 10 台服务器，单机的 QPS 在 1000，那么理论上 1 秒就可以抢完，针对微服务就可以做限流配置，避免后续无效的流量打到数据库造成不必要的压力。（可以降级和熔断）
2. 性能优化
    - 页面静态化，参与秒杀活动的商品一般都是已知的，可以针对活动页面做静态化处理，缓存到 CDN。
    - 活动预热，针对活动的活动库存可以独立出来，不和普通的商品库存共享服务，活动库存活动开始前提前加载到 redis，查询全部走缓存，最后扣减库存再视情况而定。
    - 独立部署，资源充足的情况下可以考虑针对秒杀活动单独部署一套环境
3. 防止超卖
    - 首先查询 redis 缓存库存是否充足
    - 先扣库存再落订单数据，可以防止订单生成了没有库存的超卖问题
    - 扣库存的时候先扣数据库库存，再扣减 redis 库存，保证在同一个事务里，无论两者哪一个发生了异常都会回滚。

### 怎么预防CSRF？
用csrf防止cookie被盗用，


### LinkedBlockingQueue和ConcurrentLinedQueue的区别，为什么要有两个？
有block则代表提供了阻塞api；有concurrent代表方法加了锁，线程安全；有queue则是单向队列，有deque则是双端队列；有linked是基于链表实现，有array是基于数组实现的


### 频繁GC
1. 可能是内存泄漏，内存使用完了没释放；jmap（jmap -histo  pid）看对象的存活，哪些对象数太多
2. 内存设置问题，jstat看看，根据业务，新生代、老年代和永久代的设置情况

### future，futureTask的区别
future是个接口，不同的实现是不一样的，常见的是FutureTask（线程池提交Callback）是直接依赖LockSupport.park(nanos)/unpark的，Lock锁/AQS也是依赖这个。get时会检查有没有完成，没完成会进入阻塞，等到任务的流程跑完后，会塞入结果，然后唤醒等待的线程。另一个常见的是CompletableFuture，get的时候的特点是先自旋一定次数，尝试获取结果，拿不到再进入阻塞

### select poll和epoll的区别
select和poll差不多，一个是数组，一个是链表，所以后者没有数量的限制；epoll多注册了一个ctrl事件监听。套接字是操作系统在管理，所以硬件的中断反馈给操作系统，进程从操作系统读取套接字的fd，所以有一个内存拷贝的过程，select和poll是轮询每个套接字，每次都要全部拷贝，而epoll是在初始化时拷贝，每次事件触发时直接响应，不需要再复制

### 有一个请求去调用了服务A，A中需要向数据库写入数据，其中A里面又调用了服务B，B中也向服务器写入了一些数据，当A成功调用B之后，B正常执行了，A的操作发生了异常，A操作的数据可以正常回滚，那么问题是B服务的事务如何与A保持一致呢？
1. 结合MQ消息中间件实现的可靠消息最终一致性
    - 可靠消息最终一致性，需要业务系统结合MQ消息中间件实现，在实现过程中需要保证消息的成功发送及成功消费。即需要通过业务系统控制MQ的消息状态
2. TCC补偿性事务解决方案（借助事务管理模块，做全局事务提交的决定）
    - TCC补偿性，分为三个阶段TRYING-CONFIRMING-CANCELING。每个阶段做不同的处理。
    - TRYING阶段主要是对业务系统进行检测及资源预留
    - CONFIRMING阶段是做业务提交，通过TRYING阶段执行成功后，再执行该阶段。默认如果TRYING阶段执行成功，CONFIRMING就一定能成功。
    - CANCELING阶段是回对业务做回滚，在TRYING阶段中，如果存在分支事务TRYING失败，则需要调用CANCELING将已预留的资源进行释放。
3. 最大努力通知型方案
    - 这种方案也是结合MQ进行实现，例如：通过MQ发送http请求，设置最大通知次数。达到通知次数后即不再通知。主要用在与第三方系统通讯时
4. 补偿模式
    - 提供回滚接口供调用方使用


### 订单有几个属性，用户user_id，下单日期date，满足以下场景，如何建立最少的索引
1. 查询某个用户的所有订单
2. 查询某一天的所有订单
3. 查询某一天某个用户的所有订单
    - date和user_id_date两个索引（否则就得是user_id和date_user_id两个），但date的选择性没有user_id更好，因此选前者


### TPS、RPS和QPS的区别
- TPS：Transactions Per Second（每秒传输的事物处理个数），即服务器每秒处理的事务数。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。
- QPS：Queries Per Second意思是“每秒查询率”，是一台服务器每秒能够响应的查询次数，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。
- 如果是容量场景，假设n个接口都是查询接口，且这个接口内部不会再去请求其它接口，qps=n*tps
- RPS 代表吞吐率，即 Requests Per Second，指的是某个并发用户数下单位时间内处理的请求数，等效于QPS

## 算法题
- 加油站
- k个一组翻转单链表
- 二叉树第k层偶数和
- 判断一个数组数据是否是二叉搜索树的后续遍历
- 单例模式，
- 两个list的区间交集
- 二叉树锯齿形层次遍历
- 字典序的第k小数字
- 二叉树以中序遍历方式转换成双向链表，空间O(1)
- 给定一个n*m的数组，每个位置一个分数，求左上到右下的最大分数
- 将一个无序数组插入1g个元素的有序数组中
- 对一个100g的文件去重
- 可怜的小猪
- 盛最多水的容器
- 174地下城游戏

### 实现lru
一个map（键为元素的值，值为node本身），内部放node，实现O(1)时间内判断是否在集合中；节点采用双端队列，方便删除、新增节点；
1. get：首先判断map中是否存在元素，不存在返回-1；存在则从map中get节点，把节点move2Head，返回节点的值即可
2. put：首先判断map中是否存在，不存在则新建节点并添加链表的头，并将其添加到map；存在则更新map中的值，并把节点move2Head
- 注意当判定size >= capacity时，要找到tail的前置节点curNode，remove map中的节点，并删除curNode
3. 私有方法
- deleteNode：找到pre和next节点，相互连接，把curNode的pre和next置为null，size--
- addHeadNode：处理前置哨兵head，让head和curNode相连，原先的head.next连接到curNode的后面
- move2Head：先deleteNode，再add2Head

### 海量的号码存在一个大文件里，机器内存只有512M，怎么去重
用一个bit代表一个数字

### 有2T的文件，一半以上数据重复，1T的内存核无限的CPU，如何去重
维护很多个二叉树，存在抛弃，最后再进行一次去重

### 给定m个不重复字符[a,b,c]，以及一个长度为n的字符串，问是否能在这个字符串中找到一个长度为m的连续子串，要求子串由m个字符组成，顺序不要求
- TODO



### 设计一个内存计数器，统计有限个高频词汇的访问量，实现统计和查询两个方法
1. 用threadLocal保存每个线程的long副本，无锁自增。需要解决get求值问题，需要注意
 - 需要try catch，以免线程退出导致threadlocal销毁
 - 通过threadFactory拿到线程池创建时的所有线程和其的threadLocal变量
2. 每个线程单独统计（不需要锁和cas，直接加就行），get时累加每个线程的值
3. 并发量不大，直接用atomic包；并发大时用LongAdder，将对单个值的cas分散到数组中，自旋降低，每次get都计算数组的和



## mysql
- 为什么mysql默认是innodb
- 用户名当主键的不足（唯一标识和不可修改，没有业务含义）

- 幻读及使用MVCC及间隙锁解决幻读
- 场景：对某种场景，如何设计索引
- 联合索引abc，查询bc不会走索引吗（）
- 事物和ACID
- 隔离级别，有何不同
- 快照读和当前度
- 索引机制，为何是B+树而不是hash
- b树和b+树区别
- 最左匹配原则（联合索引取最左边的）
- B+树结构，为什么不用红黑树，聚簇索引，非聚簇索引，回表
- log有哪些（六种）？有什么用
- mysql的缺点，优化方案
- 子查询经过解析器和优化器的分解过程
- 设计一张表需要考虑什么问题
- linux是如何启动的
- 分布式事物和共识算法
- g1是怎么计算价值的，怎么知道哪些区应该回收
- JVM堆区分布
- 主线程的上下文如何传递给子线程
- 出现了use filesort怎么解决
- 索引失效的原理和场景（函数计算破坏索引的有序性）
- mysql一页多少kb（16kb）
- 


### 出现了use filesort怎么解决
- Using filesort 的含义很简单，就是使用了排序操作，出现这个选项的常见情况就是 Where 条件和 order by 子句作用在了不同的列上
- 解决：添加联合索引，联合where和order by子句的两个列即可

### log有哪些（七种）？有什么用
- 重做日志（redo log）：确保事务的持久性。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。事务开始之后就产生redo log，redo log的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入redo log文件中。
- 回滚日志（undo log）：保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读。事务开始之前，将当前是的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性
- 二进制日志（binlog）：用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步；用于数据库的基于时间点的还原；事务提交的时候，一次性将事务中的sql语句（一个事物可能对应多个sql语句）按照一定的格式记录到binlog中。
- 错误日志（errorlog）：错误日志记录着mysqld启动和停止,以及服务器在运行过程中发生的错误的相关信息。
- 慢查询日志（slow query log）：慢日志记录执行时间过长和没有使用索引的查询语句（可选项），报错select、update、delete以及insert语句，慢日志只会记录执行成功的语句。
- 一般查询日志（general log）：记录了服务器接收到的每一个查询或是命令，无论这些查询或是命令是否正确甚至是否包含语法错误
- 中继日志（relay log）： 中继日志也是二进制日志，用来给slave 库恢复


### b+树比b树的优势
- 单一节点存储的元素更多，使得查询的IO次数更少，所以也就使得它更适合做为数据库MySQL的底层数据结构了。
- 所有的查询都要查找到叶子节点，查询性能是稳定的，而B树，每个节点都可以查找到数据，所以不稳定。
- 所有的叶子节点形成了一个有序链表，更加便于查找。

### 索引失效
1. 违反最左前缀法则，如果索引有多列，要遵守最左前缀法则，即查询从索引的最左前列开始并且不跳过索引中的列
2. 在索引列上做任何操作，如计算、函数、（自动or手动）类型转换等操作，会导致索引失效从而全表扫描
3. 索引范围条件右边的列，here name = 'zhangsan' and age > 20 and pos = 'cxy'，pos不会走索引
4. 尽量使用覆盖索引
5. 使用不等于（!=、<>），会导致全表扫描
6. like以通配符开头（'%abc'）
7. 字符串不加单引号索引失效
8. or连接
9. order by、group by



### 隔离级别，有何不同
1. 读未提交（READ UNCOMMITTED）
    - 任何事务对数据的修改都会第一时间暴露给其他事务，即使事务还没有提交。会脏读
2. 读提交 （READ COMMITTED）
    - 读提交就是一个事务只能读到其他事务已经提交过的数据，也就是其他事务调用 commit 命令之后的数据。那脏数据问题迎刃而解了。但是不能解决重复读问题（两次读结果不一致）和幻读
3. 可重复读 （REPEATABLE READ）：事务不会读到其他事务对已有数据的修改，及时其他事务已提交，也就是说，事务开始时读到的已有数据是什么，在事务提交前的任意时刻，这些数据的值都是一样的。
    - 通过MVCC解决重复读问题
4. 串行化 （SERIALIZABLE）：将事务的执行变为顺序执行

### 快照读和当前读
1. 快照读：读取的是记录数据的可见版本（可能是过期的数据），不用加锁，当执行select的时候，innodb默认会执行快照读，相当于就是给你目前的状态找了一张照片，以后执行select 的时候就会返回当前照片里面的数据，当其他事务提交了也对你不造成影响，和你没关系，这就实现了可重复读了，那这个照片是什么时候生成的呢？不是开启事务的时候，是当你第一次执行select的时候，也就是说，当A开启了事务，然后没有执行任何操作，这时候B insert了一条数据然后commit,这时候A执行 select，那么返回的数据中就会有B添加的那条数据......之后无论再有其他事务commit都没有关系，因为照片已经生成了，而且不会再生成了，以后都会参考这张照片。

2. 当前读：读取的是记录数据的最新版本，并且当前读返回的记录都会加上锁，保证其他事务不会再并发的修改这条记录。
    - select * from table where ? lock in share mode; 共享锁
    - select * from table where ? for update; 排它锁
    - insert；
    - update；
    - delete；

### 幻读及使用MVCC及间隙锁解决幻读
- 幻读：同一个事务里面连续执行两次同样的sql语句，可能导致不同结果的问题，第二次sql语句可能会返回之前不存在的行。
- MVCC也会幻读
    - a事务先select，b事务insert确实会加一个gap锁，但是如果b事务commit，这个gap锁就会释放（释放后a事务可以随意操作），
    - a事务再select出来的结果在MVCC下还和第一次select一样，
    - 接着a事务不加条件地update，这个update会作用在所有行上（包括b事务新加的），
    - a事务再次select就会出现b事务中的新行，并且这个新行已经被update修改了.
    - 上面这样，事务2提交之后，事务1再次执行update，因为这个是当前读，他会读取最新的数据，包括别的事务已经提交的，所以就会导致此时前后读取的数据不一致，出现幻读。
- 事务1在update后，对该数据加锁（行锁 + 间隙锁），事务B无法插入新的数据，这样事务A在update前后数据保持一致，避免了幻读
- 结论
    - 快照读的幻读是用MVCC解决的，当前的读的幻读是用间隙锁解决的。在rr级别下，mvcc完全解决了重复读，但并不能真正的完全避免幻读，只是在部分场景下利用历史数据规避了幻读
    - 对于快照读，mysql使用mvcc利用历史数据部分避免了幻读（在某些场景看上去规避了幻读）
    - 要完全避免，需要手动加锁将快照读调整为当前读（mysql不会自动加锁），然后mysql使用next-key完全避免了幻读，比如rr下，锁1（0，2，3，4），另一个线程的insert 3即被阻塞，在rc下，另一个线程仍然可以大摇大摆的插入，如本线程再次查询比如count，则会不一致


### 读扩散和写扩散
#### 写扩散(Push)
该方式为每个用户维护一个订阅列表，记录该用户订阅的消息索引（一般为消息ID、类型、发表时间等一些元数据）。每当用户发布消息时，都会去更新其follower的订阅列表。
优点：读很轻。初始化时仅需要读取自己的inbox即可。
缺点：写很重。每发布一个消息，会导致大量的写操作。
注：一般来说，用户发布消息，并不会更新所有followers的订阅列表，仅更新在线followers即可。

#### 读扩散(Pull)
该方式为每个用户维护一个发送列表，记录该用户所有发表过的消息索引。
优点：写很轻，节省空间。用户每发布一条消息，仅需更新自己的outbox。
缺点：读操作很重，计算量大。假设你收听了1k用户，则初始化时，需要从1k个用户的outbox拉取消息，然后计算获得最新的n条消息。

#### 混合模式(Push+Pull)
该方式既为读写扩散的结合，根据用户followers的数量来决定是读扩散还是写扩散。例如followers大于1k的，则使用读扩散，否则使用写扩散。

### 为何用B+树作为索引
1. 很适合磁盘存储，能够充分利用局部性原理，磁盘预读；
2. 很低的树高度，能够存储大量数据；
3. 索引本身占用的内存很小；
4. 能够很好的支持单点查询，范围查询，有序性查询；

### 为何索引不用hash
1. Hash 索引仅仅能满足"=","IN"和"<=>"查询，不能使用范围查询。
2. Hash 索引无法被用来避免数据的排序操作。
    - 由于 Hash 索引中存放的是经过 Hash 计算之后的 Hash 值，而且Hash值的大小关系并不一定和 Hash 运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算；
3. Hash 索引不能利用部分索引键查询。
- 对于组合索引，Hash 索引在计算 Hash 值的时候是组合索引键合并后再一起计算 Hash 值，而不是单独计算 Hash 值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash 索引也无法被利用。
4. Hash 索引在任何时候都不能避免表扫描。（hash一样数据不一定一样）
5. Hash 索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高。

### MyISAM与InnoDB的索引差异
#### MyISAM 索引
MyISAM的索引与行记录是分开存储的，叫做非聚集索引（UnClustered Index）。其主键索引与普通索引没有本质差异
    - 有连续聚集的区域单独存储行记录
    - 主键索引的叶子节点，存储主键，与对应行记录的指针
    - 普通索引的叶子结点，存储索引列，与对应行记录的指针
    - 可以没有主键

#### InnoDB索引
1. InnoDB的主键索引与行记录是存储在一起的，故叫做聚集索引（Clustered Index）
    - 没有单独区域存储行记录
    - 主键索引的叶子节点，存储主键，与对应行记录（而不是指针）
    - InnoDB的PK查询是非常快的。

2. InnoDB的表必须要有聚集索引：
    - 如果表定义了PK，则PK就是聚集索引；
    - 如果表没有定义PK，则第一个非空unique列是聚集索引；
    - 否则，InnoDB会创建一个隐藏的row-id作为聚集索引；
    
    
### 为什么mysql默认是innodb
功能对比
1.功能对比
    - InnoDB支持ACID的事务4个特性，而MyISAM不支持；
    - InnoDB支持4种事务隔离级别，默认是可重复读repeatable read，MyISAM不支持；
    - InnoDB 支持crash安全恢复，MyISAM不支持；InnoDB支持外键，MyISAM不支持；
    - InnoDB支持行级别的锁粒度，MyISAM不支持，只支持表级别的锁粒度；
    - InnoDB支持MVCC，MyISAM不支持。
    - InnoDB特性上，InnoDB表最大可以64TB，支持聚簇索引、支持压缩数据存储，支持数据加密，支持查询/索引/数据高速缓存，支持自适应hash索引、空间索引，支持热备份和恢复等。
2. 性能对比
    - 读写混合模式下，随着CPU核数的增加，InnoDB的读写能力呈线性增长，在这个测试用例里，最高可达近9000的TPS，但MyISAM因为读写不能并发，它的处理能力跟核数没关系，呈一条水平线，TPS低于500。

    - 只读模式下，随着CPU核数的增加，InnoDB的读写能力呈线性增长，最高可达近14000的TPS，但MyISAM的处理能力不到3000。


### 记录锁（行锁，Record Locks）、间隙锁（Gap Locks）和临键锁（Next-Key Lock）区别
1. 记录锁：实现依赖于索引，一旦某个加锁操作没有使用到索引，那么该锁就会退化为表锁
2. 间隙锁：基于非唯一索引，锁定一段范围内的索引记录。间隙锁基于Next-Key Locking 算法，使用间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据。
    - SELECT * FROM table WHERE id BETWEN 1 AND 10 FOR UPDATE; 所有在（1，10）区间内的记录行都会被锁住，所有id 为 2、3、4、5、6、7、8、9 的数据行的插入会被阻塞，但是 1 和 10 两条记录行并不会被锁住。
3. 临键锁：可以理解为一种特殊的间隙锁，通过临建锁可以解决幻读的问题。 每个数据行上的非唯一索引列上都会存在一把临键锁，当某个事务持有该数据行的临键锁时，会锁住一段左开右闭区间的数据。需要强调的一点是，InnoDB 中行级锁是基于索引实现的，临键锁只与非唯一索引列有关，在唯一索引列（包括主键列）上不存在临键锁。

### innodb四大特性
1. 插入缓冲 （Insert Buffer/Change Buffer）：前者主要提升插入性能，后者对insert、delete和update和purge都有效。优化的是非唯一二级索引
    - 每一次的插入不是写到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，如果在则直接插入；若不在，则先放到Insert Buffer 中，再按照一定的频率进行合并操作，再写回disk。这样通常能将多个插入合并到一个操作中，目的还是减少了随机IO带来性能损耗
2. 双写机制（Double Write）：首先会将（memcpy函数）Page刷到InnoDB tablespace的一个区域中，我们称该区域为Double write Buffer，在双写到共享表空间和数据文件中。其中共享表空间（2MB）为顺序写，作为备份，磁盘为随机写，若失败则从共享表空间中恢复即可
3. 自适应哈希索引（Adaptive Hash Index，AHI）：InnoDB存储引擎会监控对表上辅助索引页（用索引键的前缀）的查询。如果观察到建立hash索引可以提升性能，就会在缓冲池建立hash索引，称之为自适应哈希索引
4. 预读 （Read Ahead）：异步将磁盘的页读取到buffer pool中，预料这些页会马上被读取到。预读请求的所有页集中在一个范围内。
    - Linear read-ahead：线性预读技术预测在buffer pool中被访问到的数据它临近的页也会很快被访问到
    - Random read-ahead: 随机预读通过buffer pool中存中的来预测哪些页可能很快会被访问，而不考虑这些页的读取顺序


### 索引覆盖
如果一个索引覆盖（包含）了所有需要查询的字段的值，这个索引就是覆盖索引。因为索引中已经包含了要查询的字段的值，因此查询的时候直接返回索引中的字段值就可以了，不需要再到表中查询，避免了对主键索引的二次查询，也就提高了查询的效率。


### order by的实现原理
1. 利用有序索引获取有序数据；
2. 文件排序。
- 在使用explain分析查询的时候，利用有序索引获取有序数据显示Using index。如果MySQL在排序的时候没有使用到索引那么就会输出using filesort，即使用文件排序。

### sort_buffer默认容量大小，超过容量怎么办？（了解sort_buffer写入文件的机制）
8M，最大16M。写入临时文件的三个时机
- 每写入一条数据写入临时文件
- 每秒线程调用写入
- 缓冲区使用超过一半时写入


## Redis
- redis单线程消费，怎么将结果原路返回？（套接字事件与redis的处理器相关联，哪个套接字发出的命令，命令回复处理器就返回给哪个套接字）
- Redis的性能瓶颈（机器内存和网络带宽，执行命令分 发送 排队 执行 返回  四个阶段，后者可以用打包多次命令，一次发送方法部分解决）
- Redis有哪些数据结构（sds，压缩表ziplist，链表linkedlist，字典hashtable，整数集合intset，跳表skiplist）
- 布隆过滤器怎么实现（bitmap和Redisson）
- redis从库查询过期键（不会主动删除，等主库的del命令，会一段时间那还能访问，但3.2以上版本会先判断是否过期，过期返回null）
- Redis的lua脚本为何是原子的（redis会为lua脚本执行创建伪客户端模拟客户端调用redis执行命令，伪客户端执行lua脚本是排他的）


### Redis pipeline为什么能提升大批量数据插入的效率
普通命令经历四个阶段：1）发送命令－〉（2）命令排队－〉（3）命令执行－〉（4）返回结果
pipeline管道机制，它能将一组Redis命令进行组装，通过一次RTT传输给Redis，并将这组Redis命令的执行结果按顺序返回给客户端


### redis过期策略
1. 定时策略：在设置key的过期时间的同时，为该key创建一个定时器，让定时器在key的过期时间来临时，对key进行删除
- 优点：保证内存被尽快释放，减少无效的缓存暂用内存
- 缺点：若过期key很多，删除这些key会占用很多的CPU时间；定时器很多，影响性能，一般不选这种
2. 惰性策略：key过期的时候不删除，每次从数据库获取key的时候去检查是否过期，若过期，则删除，返回null
- 优点：删除操作只发生在从数据库取出key的时候发生，而且只删除当前key，所以对CPU时间的占用是比较少的
- 缺点：若大量的key在超出超时时间后，很久一段时间内，都没有被获取过，此时的无效缓存是永久暂用在内存中的，那么可能发生内存泄露
3. 定期策略：每隔一段时间对设置了缓存时间的key进行检测，如果可以已经失效，则从内存中删除，如果未失效，则不作任何处理（随机取key，不遍历所有key）
- 优点：通过限制删除操作的时长和频率，来减少删除操作对CPU时间的占用--处理"定时删除"的缺点；定期删除过期key--处理"惰性删除"的缺点
- 缺点：在内存友好方面，不如"定时删除"，因为是随机遍历一些key，因此存在部分key过期，但遍历key时，没有被遍历到，过期的key仍在内存中。在CPU时间友好方面，不如"惰性删除"，定期删除也会暂用CPU性能消耗。

### 缓存和数据库一致性怎么解决（https://xie.infoq.cn/article/47241d099404a1565e168fad4）
#### 前提讨论（缓存用删除而不是更新，防止多线程竞争）
1. 先删除缓存，再更新数据库
- 可能导致数据不一致，同时有一个请求 A 进行更新操作，另一个请求 B进行查询操作。那么会出现如下情形:
（1）请求 A 进行写操作，删除缓存
（2）请求 B 查询发现缓存不存在
（3）请求 B 去数据库查询得到旧值
（4）请求 B 将旧值写入缓存
（5）请求 A 将新值写入数据库
- 此时缓存中是旧值，若不采用给缓存设置过期时间策略，该数据永远都是脏数据
2. 先更新数据库，再删除缓存
- 也可能导致数据不一致，一个请求 A 做查询操作，一个请求 B做更新操作，那么会有如下情形产生
（1）缓存刚好失效
（2）请求 A 查询数据库，得一个旧值
（3）请求 B 将新值写入数据库
（4）请求 B 删除缓存
（5）请求 A 将查到的旧值写入缓存
- 一般不会发生，理由是（3）写数据库更耗时，大多数情况下采用这种


#### 解决方案
1. 缓存延时双删：先淘汰缓存，再更新数据库，等1s后再次淘汰缓存（第二次可以异步以增加吞吐量）
2. 重试机制：解决缓存删除失败的情况
- 缓存删除失败后，把请求放入MQ，再消费MQ重试之
- 非侵入的代码，订阅binlog，做重试删除缓存

### bitmap可以做什么
bitmap是通过一个bit数组来存储特定数据的一种数据结构，最大可以存放2的32次方（512MB）
1. 可以用于排序，如1 2 3 5 7 可以用1B的数据，8位分别代表0-7，有则置1，最后遍历即可
2. 员工打卡记录，SETBIT key offset value结合GETBIT命令查看某人是否打卡，结合BITCOUNT查看某天打卡总人数


### 分布式限流器怎么实现
1. 令牌桶：一定大小的桶，每隔一段时间往里面放令牌（直到满），每个请求拿k个，拿完之后后面的请求拒绝
- Google的Guava

2. 漏斗桶：通过一个 FIFO （First in first out）的队列（有界）实现，如果请求堆积满了队列，就会触发丢弃策略。消费者以一定的速率消化这些请求
3. 固定时间窗口（Fixed window）：将时间切分成若干个时间片，每个时间片内固定处理若干个请求。假设n秒内最多处理b个请求，那么每隔n秒将计数器重置为b。请求到来时，如果计数器值足够，则扣除并请求通过，不够则触发拒绝策略。
- 缺陷：请求都在时间窗口的开头被迅速消耗，剩下的时间不处理任何请求
4. 滑动日志（Sliding Log）：滑动日志根据缓存之前接受请求对应的时间戳，与当前请求的时间戳进行计算，控制速率。这样可以严格限制请求速率。假设n秒内最多处理b个请求。那么会最多缓存 b 个通过的请求与对应的时间戳，假设这个缓存集合为B。每当有请求到来时，从B中删除掉n秒前的所有请求，查看集合是否满了，如果没满，则通过请求，并放入集合，如果满了就触发拒绝策略。
5. 滑动窗口（滑动日志 + 固定窗口）：假设n秒内最多处理b个请求。我们可以将n秒切分成每个大小为m毫秒得时间片，只有最新的时间片内缓存请求和时间戳，之前的时间片内只保留一个请求量的数字。这样可以大大优化存储，小幅度增加计算量。

#### 分布式限流
在redis上配置限流器，每个节点收到来自上游的请求后直接请求数据库，然后数据库根据限流器判断是否处理这个请求，最后返回给节点相关信息。如果请求量大，redis负载较高
1. 在节点上积攒够一定的请求量N后再去请求中心限流器，这样节点对中心化数据库的请求频次会降低为1/N。
- 缺点：请求积攒阶段这些请求就无法决定是否被处理，这样也会造成一定的延迟增加。并且如果请求十分不均匀，在积攒阶段迟迟攒不到N个，即使设置了积攒超时也会大大增加延迟
2. 认为负载均衡器会将流量十分均匀的分布在各个节点上，这样本地限流器的配置就等于全局限流器的配置除以节点数量
- 缺点：对中心化数据库的压力更小，但误差也更大，负载均衡器并不能保证流量会十分均匀地打到各个节点上，其次中心化数据库也可能对活着的节点数量统计不准确
3. 每个节点初始时请求中心限流器N个令牌，当N个令牌都消耗完了再去数据库请求N个
- 只针对令牌算法，有一定的误差


### 布隆过滤器在Redis中的应用
一个大的bit数组，几个hash函数，对健key，通过几个hash函数，计算得第k位是否为1，如果判断结果都为否，则肯定不存在；判断存在则只是可能存在
适用于：邮件&网站黑名单，新闻推荐去重，恶意攻击导致的缓存穿透，查询加速（缓存不存在再访问磁盘）

是否适合百万级别手机号和url的判断


### 什么是缓存雪崩、缓存击穿、缓存穿透？
1. 雪崩
- 如果缓在某一个时刻出现大规模的key失效，那么就会导致大量的请求打在了数据库上面，导致数据库压力巨大，如果在高并发的情况下，可能瞬间就会导致数据库宕机。这时候如果运维马上又重启数据库，马上又会有新的流量把数据库打死。这就是缓存雪崩。
- 原因：redis宕机，采用相同的过期时间
- 解决：1. 过期时间不是同一个  2. 分级缓存，每一级缓存过期时间不同  3. 热点数据缓存永不过期（不设置过期时间或借助value延时） 4. 主从哨兵或集群保证高可用
2. 击穿
- 缓存击穿是某个热点的key失效，大并发集中对其进行请求，就会造成大量请求读缓存没读到数据，从而导致高并发访问数据库，引起数据库压力剧增。这种现象就叫做缓存击穿。
- 解决：1. 永不过期  2. 缓存失效后，通过互斥锁或队列控制数据写缓存的线程数量，如某个key只 允许一个线程访问，其他阻塞等待
3. 穿透
- 指用户请求的数据在缓存中不存在即没有命中，同时在数据库中也不存在，导致用户每次请求该数据都要去数据库中查询一遍。如果有恶意攻击者不断请求系统中不存在的数据，会导致短时间大量请求落在数据库上，造成数据库压力过大，甚至导致数据库承受不住而宕机崩溃。
- 解决：1. 布隆过滤器：数据库中的所有key存放在布隆过滤器中，不存在直接返回  2. 无效的key存放入redis中，value为null（不能解决随机key问题）



### 跳表怎么实现的 ，为何不用红黑树，跳表有何优势，时间复杂度是多少
不用红黑树：1. 复杂度一样，实现更简单  2. zrange更方便  3. 更少的内存占用（可以少一些层） 
实现：层（随机生成1-32的数，数越大，出现几率越小），前进指针，后退指针，跨度（记录两个节点之间的距离），分值和对象
时间复杂度：插入、删除平均为log(n)，最坏是O(n)


### sds怎么实现的
1. len记录长度，free未用长度和buf[]存放字符，尾部也要加\0
2. 杜绝缓冲区溢出：先检查SDS的空间是否满足修改的需求，若不满足，则API会自动将SDS的空间扩展以至于能够放下src
3. 减少修改字符串时带来的内存重分配次数：
- C语言在字符串增长操作前，要先扩容，否则会发生缓冲区溢出字符串缩长操作前，要先释放空间，否则会内存泄露
- 空间预分配：在对SDS增长时，检查free够不够用，不够用触发扩容若增长后len小于1M，则分配free = len的额外空间若len 大于1M，则分配free = 1M的额外空间
- 惰性空间释放：对SDS缩短时，把空闲空间记录在free中，并不释放
4. 二进制安全：
- C字符串存在二进制安全的问题，它职能保存文本数据，而不能保存像图片、音频、视频压缩文件等二进制数据，因为遇到'\0'就是一个结束了的C字符串。
- 而SDS的API都是二进制安全的，所有API以处理二进制的方式来处理SDS存放的buf数组里的数据，程序不会对其中的数据做任何限制、过滤、或者转义，数据在写入时是怎么样的，被读取时就是什么样。这也是将SDS的buf数组叫做字节数组的原因——Redis不是用这个数组来保存字符，而使用它来直接保存二进制数据。


### Redis如何做分布式锁以及和zk锁的区别
#### Redis的锁
1. setNX（set if not exist）或set key value nx px 2000，其中px用来指定过期时间。
2. redlock解法：在大半的节点获取分布式锁，如果获取时间小于锁过期时间，代表获取锁成功。否则创建失败，依次删除锁（防止加锁请求发送成功，结果返回丢失）。如果别人已经建立了，就不断轮询获取锁
3. 开源框架Redission
 - 所有指令通过Lua脚本执行，Redis执行Lua脚本是原子的
 - 利用WatchDog概念，会在获取锁之后，每隔1/3（如10s）的过期时间就把锁的过期时间延长（每过10s过期时间延长至30s）。比不设置超时时间的好处是当宕机之后，看门狗消失，30s后锁过期，其他进程就能再获取锁了
 
### zk的一致性
- zk不保证强一致性，只保证顺序一致，若于强一致，比最终一致强得多
- zk的写是线性一致（强一致）的，换句话说，每次写入将在客户端发出请求和接收相应响应之间的某个时间点自动生效。
- zk的读不需要仲裁，直接返回，可能会读到旧数据

#### zk的锁
1. 每个线程获取锁就是在 ZK 创建一个临时有序的节点，比如在 /lock/ 目录下
2. 创建成功后，获取/lock下所有临时节点，判断当前线程创建的节点是否是序号最小的
3. 最小的线程获取锁成功，其他线程对前一个节点添加事件监听，锁释放后会对下一个节点进行唤醒，然后重复2

#### 区别
1. 服务端性能
- zk基于Zab协议，需要一半的节点ACK，才算写入成功，吞吐量低
- Redis基于，只写master就算成功，吞吐量高
2. 客户端性能
- Zk由于有通知机制，获取锁的过程，添加一个监听器。避免了轮询，性能消耗小
- Redis并没有通知机制，只能使用类似CAS的轮询，对客户端压力较大
3. 可靠性
- redis追求吞吐量，可靠性上稍逊，即使用了Redlock，在极端情况下也不能保证一致性
- zk有zab协议控制数据的一致性



### 如何解决redis热点key问题
自己统计，提前预热等，加入二级缓存或集群备份key解决
京东hotkey也可以解决

### Redis为什么快，为什么能达到10w qps
- 基于内存操作
- IO多路复用技术
- 单线程处理网络请求（6.0新增多线程）
- 使用管道能增加qps
- 其他业务会再fork新进程处理，如rehash，写日志等

## 系统设计
- system-design-primer

## 操作系统
- 1000个并发线程，10台机器，每个4核，设计线程池大小
- 操作系统IO模型
- IO多路复用
- 线程和进程区别
- 生产者消费者模型
- 内存分配算法
- 页结构
- 


## 计算机网络
- http和https区别
- http状态码，2xx和3xx分别是什么状态
- 线上500如何排查
- 三次握手，四次挥手
- 为什么会有close-wait
- 从输入url到页面加载完毕过程，DNS寻址
- tcp如何实现拥塞控制
- 粘包和丢包
- http post的两次发送